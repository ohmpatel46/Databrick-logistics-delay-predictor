{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0083a24e-25ce-403a-8b6a-93a24a4147e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Importing SQL Table via SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e55618f9-68b2-4658-aa6b-4b9f9eb45961",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "437b8adf-5d4b-4d2a-9bca-e58c7fb8b08b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b3babba-c714-402b-a483-c8cc50f30768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = spark.sql(\"SELECT * FROM workspace.default.train\")\n",
    "df.show(5)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c20d9ec0-a9fa-454f-bffe-fcdf2132faae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Preliminary EDA with SparkSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "754766c8-5e85-46dc-8922-a25bbd2f58b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Checking total number of records and column names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8b01894-2e45-474c-8f66-04cd7a1685a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Number of records\n",
    "print(\"Total records:\", df.count())\n",
    "\n",
    "# Column list\n",
    "print(\"Columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "101f4721-c898-481a-bdc5-66096818bb14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Analyzing class distribution for delivery status (on time vs delayed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7306769-dd9f-43d9-a454-d37d93532ebe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count of each class in Reached.on.Time_Y.N\n",
    "df.groupBy(\"`Reached.on.Time_Y.N`\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6d10265-97d9-475d-ab01-8438f913c7e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Viewing summary statistics for numeric features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03cfcf25-7ba8-415b-a57d-d2a48412f897",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Describe numeric fields like Weight_in_gms and Customer_rating\n",
    "df.select(\"Weight_in_gms\", \"Customer_rating\").describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50bf8ee5-c5c2-4dd5-8b4f-1ade9b7054dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Exploring delivery delay distribution across warehouse blocks and modes of shipment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8160efdc-91ba-4847-bd5e-6c90a9bd4661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Delays grouped by warehouse block\n",
    "df.groupBy(\"Warehouse_block\", \"`Reached.on.Time_Y.N`\").count().orderBy(\"Warehouse_block\").show()\n",
    "\n",
    "# Delays grouped by mode of shipment\n",
    "df.groupBy(\"Mode_of_Shipment\", \"`Reached.on.Time_Y.N`\").count().orderBy(\"Mode_of_Shipment\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bba4cfa-a98b-464e-a436-01840de96781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Checking average shipment weight based on delivery delay status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1f25ffc-c67f-499c-b12b-3209c095d76d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df.groupBy(\"`Reached.on.Time_Y.N`\").agg(avg(\"Weight_in_gms\").alias(\"Avg_Weight\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03cde0c0-61e5-444e-a2c8-489f260f0efd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### What Did We Learn from the Data?\n",
    "\n",
    "- A majority of deliveries (~60%) were delayed (`6563` out of `10999`).\n",
    "- Weight appears to correlate with delays: on-time deliveries have a higher average weight (~4168g vs ~3272g).\n",
    "- Warehouse F has the highest number of both on-time and delayed deliveries, suggesting it handles more volume overall.\n",
    "- Shipments by ship show a higher delay count compared to flights and roads — could indicate slower or more unreliable logistics mode.\n",
    "- Customer ratings are roughly centered around 3 (mean ~2.99), so they may not be a strong predictive feature, but we’ll include them for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebd90963-3aa4-44bd-9fc6-ed5640fe5d5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Building the ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3291d3e8-bdf9-4886-bd3b-03cd27eab82e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Converting data to Pandas Dataframe for training (Databricks Community Edition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c5a8baa-3843-46cd-89f5-744a602b12fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "selected_cols = [\n",
    "    \"Warehouse_block\",\n",
    "    \"Mode_of_Shipment\",\n",
    "    \"Product_importance\",\n",
    "    \"Customer_rating\",\n",
    "    \"Customer_care_calls\",\n",
    "    \"Cost_of_the_Product\",\n",
    "    \"Prior_purchases\",\n",
    "    \"Discount_offered\",\n",
    "    \"Weight_in_gms\",\n",
    "    \"`Reached.on.Time_Y.N`\"\n",
    "]\n",
    "\n",
    "# Subset Spark DataFrame and convert to Pandas\n",
    "pdf = df.select(*selected_cols).toPandas()\n",
    "\n",
    "# Preview Pandas DataFrame\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f50f8661-4fc8-40c8-9635-3f6b37420da7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9d3a18e-4773-41c5-8c35-4b6d283e7e3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caaa3f2e-f651-46e4-9ad2-b68957ae5bd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_model = pdf.copy()\n",
    "\n",
    "categorical_cols = [\"Warehouse_block\", \"Mode_of_Shipment\", \"Product_importance\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df_model[col] = le.fit_transform(df_model[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a9a4852-19e0-4cdf-91d6-402558bac5f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Seperating Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fc73f18-74f3-4157-8a84-eb55c4cec14c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = df_model.drop(\"Reached.on.Time_Y.N\", axis=1)\n",
    "y = df_model[\"Reached.on.Time_Y.N\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3725027-bfeb-4f18-91c8-8ad5f1729f6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9374ac97-65a3-4cce-a6cc-9e1b542d3e4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19751428-6731-46d2-a749-4545b91a882d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Defining Sweep Parameters for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "977b3b04-c7f0-451f-b1ad-5e26970b1e62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76bda6d3-2dc0-44e9-bb30-ca4bed9f9c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Initializing Model and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f511019-f895-4505-aa33-099494dab2c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=3,             # 3-fold cross-validation\n",
    "                           scoring='f1_weighted',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7218e644-a42c-4bff-a723-0212313ff342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    # Log dataset information\n",
    "    mlflow.log_param(\"train_samples\", len(X_train))\n",
    "    mlflow.log_param(\"test_samples\", len(X_test))\n",
    "    mlflow.log_param(\"n_features\", X_train.shape[1])\n",
    "    mlflow.log_param(\"target_classes\", len(np.unique(y_train)))\n",
    "\n",
    "    # Log model metadata\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"cv_folds\", grid_search.cv if hasattr(grid_search, 'cv') else 5)\n",
    "\n",
    "    # === TRACK EACH PARAMETER COMBINATION ===\n",
    "\n",
    "    param_combinations = list(ParameterGrid(grid_search.param_grid))\n",
    "    mlflow.log_param(\"total_combinations\", len(param_combinations))\n",
    "    \n",
    "    print(f\"Testing {len(param_combinations)} parameter combinations...\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    # Manually iterate through each parameter combination\n",
    "    for i, params in enumerate(param_combinations):\n",
    "        print(f\"Testing combination {i+1}/{len(param_combinations)}: {params}\")\n",
    "        \n",
    "        # Create model with current parameters\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        rf_model = RandomForestClassifier(**params, random_state=42)\n",
    "        \n",
    "        # Perform cross-validation for this combination\n",
    "        cv_scores_acc = cross_val_score(rf_model, X_train, y_train, \n",
    "                                       cv=grid_search.cv if hasattr(grid_search, 'cv') else 5, \n",
    "                                       scoring='accuracy')\n",
    "        cv_scores_f1 = cross_val_score(rf_model, X_train, y_train, \n",
    "                                      cv=grid_search.cv if hasattr(grid_search, 'cv') else 5, \n",
    "                                      scoring='f1_weighted')\n",
    "        \n",
    "        # Calculate mean scores\n",
    "        mean_cv_acc = cv_scores_acc.mean()\n",
    "        mean_cv_f1 = cv_scores_f1.mean()\n",
    "        std_cv_acc = cv_scores_acc.std()\n",
    "        std_cv_f1 = cv_scores_f1.std()\n",
    "        \n",
    "        # Log metrics for this parameter combination (using step for time series)\n",
    "        mlflow.log_metric(\"cv_accuracy_mean\", mean_cv_acc, step=i)\n",
    "        mlflow.log_metric(\"cv_f1_mean\", mean_cv_f1, step=i)\n",
    "        mlflow.log_metric(\"cv_accuracy_std\", std_cv_acc, step=i)\n",
    "        mlflow.log_metric(\"cv_f1_std\", std_cv_f1, step=i)\n",
    "        \n",
    "        # Log individual fold scores\n",
    "        for fold_idx, (acc_score, f1_score) in enumerate(zip(cv_scores_acc, cv_scores_f1)):\n",
    "            mlflow.log_metric(f\"fold_{fold_idx}_accuracy\", acc_score, step=i)\n",
    "            mlflow.log_metric(f\"fold_{fold_idx}_f1\", f1_score, step=i)\n",
    "        \n",
    "        # Log parameters for this combination\n",
    "        param_string = \"_\".join([f\"{k}={v}\" for k, v in params.items()])\n",
    "        mlflow.log_param(f\"combination_{i}_params\", param_string)\n",
    "        \n",
    "        # Track best model\n",
    "        if mean_cv_acc > best_score:  # You can change this to f1 if preferred\n",
    "            best_score = mean_cv_acc\n",
    "            best_params = params\n",
    "            best_model = rf_model\n",
    "        \n",
    "        print(f\"  → CV Accuracy: {mean_cv_acc:.4f} (±{std_cv_acc:.4f})\")\n",
    "        print(f\"  → CV F1: {mean_cv_f1:.4f} (±{std_cv_f1:.4f})\")\n",
    "    \n",
    "    # Train the best model on full training data\n",
    "    print(f\"\\nBest parameters found: {best_params}\")\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Log best parameters\n",
    "    for param_name, param_value in best_params.items():\n",
    "        mlflow.log_param(f\"best_{param_name}\", param_value)\n",
    "    \n",
    "    mlflow.log_metric(\"best_cv_score\", best_score)\n",
    "    \n",
    "    # Make predictions with best model\n",
    "    best_rf = best_model\n",
    "    y_pred_tuned = best_rf.predict(X_test)\n",
    "    \n",
    "    from sklearn.metrics import f1_score  # Re-import to override the float\n",
    "\n",
    "    # Evaluate performance on test set\n",
    "    acc = accuracy_score(y_test, y_pred_tuned)\n",
    "    f1_score_value = f1_score(y_test, y_pred_tuned, average='weighted')\n",
    "\n",
    "    # Log final test metrics\n",
    "    mlflow.log_metric(\"final_test_accuracy\", acc)\n",
    "    mlflow.log_metric(\"final_test_f1_score\", f1_score_value)\n",
    "\n",
    "    # Log model with input signature\n",
    "    signature = infer_signature(X_train, y_pred_tuned)\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=best_rf, \n",
    "        artifact_path=\"model\",\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    # Print final results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL RESULTS:\")\n",
    "    print(f\"Best CV Score: {best_score:.4f}\")\n",
    "    print(f\"Final Test Accuracy: {acc:.4f}\")\n",
    "    print(f\"Final Test F1-score: {f1:.4f}\")\n",
    "    print(\"Model logged to MLflow\")\n",
    "    print(f\"All {len(param_combinations)} parameter combinations tracked!\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15496348-be1e-4c36-9f5c-268bb30e687e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Visualizing Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c579edc-1817-4386-9b3d-500dd591eb79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Get feature importances from the best model\n",
    "importances = best_rf.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title(\"Feature Importances - Best Random Forest Model\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96ae0297-f3a0-4903-9efc-3f52060083ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Importance Insights (Tuned Random Forest)\n",
    "\n",
    "- Discount Offered and Weight in gms are the most influential features, together accounting for over 70% of the model’s predictive power. This indicates that heavier shipments and larger discounts are strongly associated with delivery delays.\n",
    "- Cost of the Product and Prior Purchases also contribute meaningfully, suggesting pricing and customer loyalty may influence delivery performance.\n",
    "- Features such as Mode of Shipment, Product Importance, and Customer Rating had minimal impact on predictions, implying they may be less predictive in this dataset.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Logistics_Delay_Predictor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
